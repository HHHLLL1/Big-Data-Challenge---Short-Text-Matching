{"cells":[{"outputs":[{"output_type":"stream","text":"bytedance\r\n","name":"stdout"}],"execution_count":1,"source":"# 查看当前挂载的数据集目录\n!ls /home/kesci/input/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"id":"E531A0F16BB241618292541299324F68","scrolled":false}},{"outputs":[{"output_type":"stream","text":"doc_test_x.npy\t\t  lr_ct.csv\r\ndoc_train_x.npy\t\t  lr_doc2vec_last500w.csv\r\ndoc_train_y.npy\t\t  lr_doc2vec_one500w.csv\r\nfasttext.csv\t\t  model11.bin\r\nfasttext_fist1000W.csv\t  model.bin\r\nfasttext_lrct.csv\t  test_feature.npy\r\nkesci_submit\t\t  test.txt\r\nlabeled_content\t\t  train.txt\r\nlgb_doc2vec_last500w.csv  valid.txt\r\nlinear_tfidf.csv\t  x_train_feature_last1000W.npy\r\nlost+found\t\t  x_train_test_feature_last1000W.npy\r\nlr_ct_1000wEoch.csv\t  y_train_feature_last1000W.npy\r\nlr_ct_100万.csv\t\t  y_train_test_feature_last1000W.npy\r\nlr_ct_500wEach.csv\r\n","name":"stdout"}],"execution_count":2,"source":"# 查看个人持久化工作区文件\n!ls /home/kesci/work/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"id":"65049DC60A054A358F17CEEB1C274B77","scrolled":false}},{"outputs":[],"execution_count":3,"source":"# 查看当前kernerl下的package\n# !pip list --format=columns","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"id":"06E3BB1B7DA2443993F643B76A864DA8","scrolled":false}},{"outputs":[],"execution_count":4,"source":"# 显示cell运行时长\n%load_ext klab-autotime","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"id":"AC222B6AB36C4955A13D503FF421653C","scrolled":false}},{"metadata":{"id":"C8E2E4E2721A4BE988261A2CA33A5E3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 1.14 s\n","name":"stdout"}],"source":"import numpy as np\r\nimport pandas as pd\r\nimport time\r\nimport math\r\nfrom sklearn.model_selection import KFold\r\nfrom fastText import train_supervised\r\nfrom sklearn import metrics\r\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\r\nimport lightgbm as lgb\r\nimport Levenshtein\r\nimport gc","execution_count":5},{"metadata":{"id":"5AEBCA26AE46449699687D4645762D53","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 9.93 s\n","name":"stdout"}],"source":"path=\"/home/kesci/input/bytedance/first-round/\"\r\ntrain = pd.read_csv(path+'train.csv', header=None, chunksize=10000000)\r\ntest = pd.read_csv(path+'test.csv', header=None)\r\npre_df = test[[0, 2]]","execution_count":6},{"metadata":{"id":"EB6571721FDC49468B84B3C4ADCA92DE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 23.8 ms\n","name":"stdout"}],"source":"def lcsubstr_lens(s1, s2): \r\n    m=[[0 for i in range(len(s2)+1)]  for j in range(len(s1)+1)]  #生成0矩阵，为方便后续计算，比字符串长度多了一列\r\n    mmax=0   #最长匹配的长度\r\n    p=0  #最长匹配对应在s1中的最后一位\r\n    for i in range(len(s1)):\r\n        for j in range(len(s2)):\r\n            if s1[i]==s2[j]:\r\n                m[i+1][j+1]=m[i][j]+1\r\n                if m[i+1][j+1]>mmax:\r\n                    mmax=m[i+1][j+1]\r\n                    p=i+1\r\n    return mmax\r\n\r\n\r\n#\r\ndef lcseque_lens(s1, s2): \r\n     # 生成字符串长度加1的0矩阵，m用来保存对应位置匹配的结果\r\n    m = [ [ 0 for x in range(len(s2)+1) ] for y in range(len(s1)+1) ] \r\n    # d用来记录转移方向\r\n    d = [ [ None for x in range(len(s2)+1) ] for y in range(len(s1)+1) ] \r\n\r\n    for p1 in range(len(s1)): \r\n        for p2 in range(len(s2)): \r\n            if s1[p1] == s2[p2]:            #字符匹配成功，则该位置的值为左上方的值加1\r\n                m[p1+1][p2+1] = m[p1][p2]+1\r\n                d[p1+1][p2+1] = 'ok'          \r\n            elif m[p1+1][p2] > m[p1][p2+1]:  #左值大于上值，则该位置的值为左值，并标记回溯时的方向\r\n                m[p1+1][p2+1] = m[p1+1][p2] \r\n                d[p1+1][p2+1] = 'left'          \r\n            else:                           #上值大于左值，则该位置的值为上值，并标记方向up\r\n                m[p1+1][p2+1] = m[p1][p2+1]   \r\n                d[p1+1][p2+1] = 'up'         \r\n    (p1, p2) = (len(s1), len(s2)) \r\n    s = [] \r\n    while m[p1][p2]:    #不为None时\r\n        c = d[p1][p2]\r\n        if c == 'ok':   #匹配成功，插入该字符，并向左上角找下一个\r\n            s.append(s1[p1-1])\r\n            p1 -= 1\r\n            p2 -= 1 \r\n        if c == 'left':  #根据标记，向左找下一个\r\n            p2 -= 1\r\n        if c == 'up':   #根据标记，向上找下一个\r\n            p1 -= 1\r\n    return len(s)\r\n    \r\ndef compute_cosine(text_a, text_b):\r\n    # 找单词及词频\r\n    words1 = text_a.split(' ')\r\n    words2 = text_b.split(' ')\r\n    # print(words1)\r\n    words1_dict = {}\r\n    words2_dict = {}\r\n    for word in words1:\r\n        # word = word.strip(\",.?!;\")\r\n        word = word.lower()\r\n        # print(word)\r\n        if word != '' and word in words1_dict: # 这里改动了\r\n            num = words1_dict[word]\r\n            words1_dict[word] = num + 1\r\n        elif word != '':\r\n            words1_dict[word] = 1\r\n        else:\r\n            continue\r\n    for word in words2:\r\n        # word = word.strip(\",.?!;\")\r\n        word = word.lower()\r\n        if word != '' and word in words2_dict:\r\n            num = words2_dict[word]\r\n            words2_dict[word] = num + 1\r\n        elif word != '':\r\n            words2_dict[word] = 1\r\n        else:\r\n            continue\r\n\r\n    # 排序\r\n    dic1 = sorted(words1_dict.items(), key=lambda asd: asd[1], reverse=True)\r\n    dic2 = sorted(words2_dict.items(), key=lambda asd: asd[1], reverse=True)\r\n\r\n    # 得到词向量\r\n    words_key = []\r\n    for i in range(len(dic1)):\r\n        words_key.append(dic1[i][0])  # 向数组中添加元素\r\n    for i in range(len(dic2)):\r\n        if dic2[i][0] in words_key:\r\n            # print 'has_key', dic2[i][0]\r\n            pass\r\n        else:  # 合并\r\n            words_key.append(dic2[i][0])\r\n    # print(words_key)\r\n    vect1 = []\r\n    vect2 = []\r\n    for word in words_key:\r\n        if word in words1_dict:\r\n            vect1.append(words1_dict[word])\r\n        else:\r\n            vect1.append(0)\r\n        if word in words2_dict:\r\n            vect2.append(words2_dict[word])\r\n        else:\r\n            vect2.append(0)\r\n\r\n    # 计算余弦相似度\r\n    sum = 0\r\n    sq1 = 0\r\n    sq2 = 0\r\n    for i in range(len(vect1)):\r\n        sum += vect1[i] * vect2[i]\r\n        sq1 += pow(vect1[i], 2)\r\n        sq2 += pow(vect2[i], 2)\r\n    try:\r\n        result = round(float(sum) / (math.sqrt(sq1) * math.sqrt(sq2)), 2)\r\n    except ZeroDivisionError:\r\n        result = 0.0\r\n    return result\r\n\r\ndef Pehrson(text_a, text_b):\r\n    # 找单词及词频\r\n    words1 = text_a.split(' ')\r\n    words2 = text_b.split(' ')\r\n    # print(words1)\r\n    words1_dict = {}\r\n    words2_dict = {}\r\n    for word in words1:\r\n        # word = word.strip(\",.?!;\")\r\n        word = word.lower()\r\n        # print(word)\r\n        if word != '' and word in words1_dict: # 这里改动了\r\n            num = words1_dict[word]\r\n            words1_dict[word] = num + 1\r\n        elif word != '':\r\n            words1_dict[word] = 1\r\n        else:\r\n            continue\r\n    for word in words2:\r\n        # word = word.strip(\",.?!;\")\r\n        word = word.lower()\r\n        if word != '' and word in words2_dict:\r\n            num = words2_dict[word]\r\n            words2_dict[word] = num + 1\r\n        elif word != '':\r\n            words2_dict[word] = 1\r\n        else:\r\n            continue\r\n\r\n    # 排序\r\n    dic1 = sorted(words1_dict.items(), key=lambda asd: asd[1], reverse=True)\r\n    dic2 = sorted(words2_dict.items(), key=lambda asd: asd[1], reverse=True)\r\n\r\n    # 得到词向量\r\n    words_key = []\r\n    for i in range(len(dic1)):\r\n        words_key.append(dic1[i][0])  # 向数组中添加元素\r\n    for i in range(len(dic2)):\r\n        if dic2[i][0] in words_key:\r\n            # print 'has_key', dic2[i][0]\r\n            pass\r\n        else:  # 合并\r\n            words_key.append(dic2[i][0])\r\n    # print(words_key)\r\n    vect1 = []\r\n    vect2 = []\r\n    for word in words_key:\r\n        if word in words1_dict:\r\n            vect1.append(words1_dict[word])\r\n        else:\r\n            vect1.append(0)\r\n        if word in words2_dict:\r\n            vect2.append(words2_dict[word])\r\n        else:\r\n            vect2.append(0)\r\n\r\n    # 计算Pehrson\r\n    x = np.vstack([vect1, vect2])\r\n    return np.corrcoef(x)[0][1]","execution_count":7},{"metadata":{"id":"111D6459EB1D4B4488F065D9386D77FB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 25.3 ms\n","name":"stdout"}],"source":"def getfeature(df):\r\n    # df.drop_duplicates(inplace=True)\r\n    since = time.time()\r\n    \r\n    df['query_len'] = df.apply(lambda x: len(x[1].split(' ')), axis=1)\r\n    df['query_len'] = df['query_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('1complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def get_query_unique(x):\r\n        a = len(set(x[1].split(' '))-set(x[3].split(' ')))\r\n        return a\r\n    df['query_unique'] = df.apply(get_query_unique, axis=1)\r\n    df['query_unique'] = df['query_unique'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#####################################3\r\n    print('2complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['title_len'] = df.apply(lambda x: len(x[3].split(' ')), axis=1)\r\n    df['title_len'] = df['title_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since######################################\r\n    print('3complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def get_query_unique(x):\r\n        a = len(set(x[3].split(' '))-set(x[1].split(' ')))\r\n        return a\r\n    \r\n    df['title_unique'] = df.apply(get_query_unique, axis=1)\r\n    df['title_unique'] = df['title_unique'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['dif'] = (df['query_len'] - df['title_len']).abs()\r\n    df['dif'] = df['dif'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('4complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def query_title_same_len(x):\r\n        a = len(x[3].split(' ') and x[1].split(' '))\r\n        return a\r\n    df['query_title_same_len'] = df.apply(query_title_same_len, axis=1)\r\n    df['query_title_same_len'] = df['query_title_same_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('5complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n\r\n    def samelen_query_rate(x):\r\n        a = len(set(x[1].split(' ')) & set(x[3].split(' ')))\r\n        return a/len(x[1].split(' '))\r\n    df['samelen_query_rate'] = df.apply(samelen_query_rate, axis=1)\r\n    df['samelen_query_rate'] = df['samelen_query_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('6complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def samelen_title_rate(x):\r\n        a = len(set(x[1].split(' ')) & set(x[3].split(' ')))\r\n        return a/len(x[3].split(' '))\r\n    df['samelen_title_rate'] = df.apply(samelen_title_rate, axis=1)\r\n    df['samelen_title_rate'] = df['samelen_title_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('7complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    \r\n    def q_t_all_len(x):\r\n        a = len(x[1].split(' ')) + len(x[3].split(' '))\r\n        return a\r\n    df['q_t_all_len'] = df.apply(q_t_all_len, axis=1)\r\n    df['q_t_all_len'] = df['q_t_all_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since##########################################\r\n    print('8complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def q_t_all_word_len(x):\r\n        a = len(set(x[1].split(' ')) | set(x[3].split(' ')))\r\n        return a\r\n    df['q_t_all_word_len'] = df.apply(q_t_all_word_len, axis=1)\r\n    df['q_t_all_word_len'] = df['q_t_all_word_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('9complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['q_t_diff_len'] = df.apply(lambda x: len(set(x[1].split(' '))^set(x[3].split(' '))), axis=1)\r\n    df['q_t_diff_len'] = df['q_t_diff_len'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('9complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def q_t_diff_q_rate(x):\r\n        a = len(set(x[1].split(' '))^set(x[3].split(' ')))\r\n        return np.float32(a/len(x[1].split(' ')))\r\n    df['q_t_diff_q_rate'] = df.apply(q_t_diff_q_rate, axis=1)\r\n    df['q_t_diff_q_rate'] = df['q_t_diff_q_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('10complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def q_t_diff_t_rate(x):\r\n        a = len(set(x[1].split(' '))^set(x[3].split(' ')))\r\n        return np.float32(a/len(x[3].split(' ')))\r\n    df['q_t_diff_t_rate'] = df.apply(q_t_diff_t_rate, axis=1)\r\n    df['q_t_diff_t_rate'] = df['q_t_diff_t_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('11complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n\r\n    \r\n    def query_diff_title(x):\r\n        a = len(set(x[1].split(' ')) - (set(x[1].split(' ')) & set(x[3].split(' '))))\r\n        return np.int32(a)\r\n    df['query_diff_title'] = df.apply(query_diff_title, axis=1)\r\n    df['query_diff_title'] = df['query_diff_title'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('12complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def query_diff_title_rate(x):\r\n        a = len(set(x[1].split(' ')) - (set(x[1].split(' ')) & set(x[3].split(' '))))\r\n        return np.float32(a/len(x[3].split(' ')))\r\n    df['query_diff_title_rate'] = df.apply(query_diff_title_rate, axis=1)\r\n    df['query_diff_title_rate'] = df['query_diff_title_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('13complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def title_diff_query(x):\r\n        a = len(set(x[1].split(' ')) - (set(x[1].split(' ')) & set(x[3].split(' '))))\r\n        return np.int32(a)\r\n    df['title_diff_query'] = df.apply(title_diff_query, axis=1)\r\n    df['title_diff_query'] = df['title_diff_query'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('14complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def title_diff_query_rate(x):\r\n        a = len(set(x[1].split(' ')) - (set(x[1].split(' ')) & set(x[3].split(' '))))\r\n        return np.float32(a/len(x[3].split(' ')))\r\n    df['title_diff_query_rate'] = df.apply(title_diff_query_rate, axis=1)\r\n    df['title_diff_query_rate'] = df['title_diff_query_rate'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since\r\n    print('15complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def dice(x):\r\n        a1 = len(set(x[1].split(' ')) & set(x[3].split(' ')))\r\n        a2 = len(set(x[1].split(' '))) + len(set(x[3].split(' ')))\r\n        return np.float32(2*a1/a2)\r\n    df['dice'] = df.apply(dice, axis=1)\r\n    df['dice'] = df['dice'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('16complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    def jaccord(x):\r\n        a1 = len(set(x[1].split(' ')) & set(x[3].split(' ')))\r\n        a2 = len(set(x[1].split(' ')) | set(x[3].split(' ')))\r\n        return np.float32(a1/a2)\r\n    df['jaccord'] = df.apply(jaccord, axis=1)\r\n    df['jaccord'] = df['jaccord'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('17complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['query_count'] = df.groupby(1)[1].transform('count')\r\n    df['query_count'] = df['query_count'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('18complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['title_count'] = df.groupby(3)[3].transform('count')\r\n    df['title_count'] = df['title_count'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('19complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['lcseque_lens'] = df.apply(lambda x: lcseque_lens(x[1], x[3]), axis=1)\r\n    df['lcseque_lens'] = df['lcseque_lens'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('20complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['lcsubstr_lens'] = df.apply(lambda x: lcsubstr_lens(x[1], x[3]), axis=1)\r\n    df['lcsubstr_lens'] = df['lcsubstr_lens'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('21complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n\r\n    df['ratio'] = df.apply(lambda x: Levenshtein.ratio(x[1], x[3]), axis=1)\r\n    df['ratio'] = df['ratio'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('22complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n\r\n    df['jaro'] = df.apply(lambda x: Levenshtein.jaro(x[1], x[3]), axis=1)\r\n    df['jaro'] = df['jaro'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('23complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['jaro_winkler'] = df.apply(lambda x: Levenshtein.jaro_winkler(x[1], x[3]), axis=1)\r\n    df['jaro_winkler'] = df['jaro_winkler'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('24complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n\r\n    df['cosine_similarity'] = df.apply(lambda x: compute_cosine(x[1], x[3]), axis=1)\r\n    df['cosine_similarity'] = df['cosine_similarity'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('25complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n\r\n    df['levenshtein'] = df.apply(lambda x: Levenshtein.distance(x[1], x[3]), axis=1)\r\n    df['levenshtein'] = df['levenshtein'].astype(np.int32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('26complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    \r\n    df['Pehrson'] = df.apply(lambda x:Pehrson(x[1], x[3]), axis=1)\r\n    df['Pehrson'] = df['Pehrson'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since#######################################\r\n    print('27complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n    since = time.time()\r\n    \r\n    df['list_dis'] = df.apply(lambda x: Levenshtein.seqratio(x[1].split(' '), x[3].split(' ')), axis=1)\r\n    df['list_dis'] = df['list_dis'].astype(np.float32)\r\n    \r\n    time_elapsed = time.time() - since\r\n    print('28complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n    \r\n\r\n    try:\r\n        df.drop([0, 1, 2, 3, 4], axis=1, inplace=True)\r\n    except:\r\n        df.drop([0, 1, 2, 3], axis=1, inplace=True)\r\n        \r\n    return df","execution_count":8},{"metadata":{"id":"A3AACF2FA81F44B6BB7C83626D6309D4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"第10次处理开始\n训练集测试集合并\n合并完成，提取特征\n1complete in 5m 4s\n2complete in 8m 14s\n3complete in 4m 49s\ncomplete in 8m 28s\n4complete in 0m 0s\n5complete in 7m 15s\n6complete in 10m 58s\n7complete in 10m 46s\n8complete in 7m 13s\n9complete in 8m 17s\n9complete in 8m 38s\n10complete in 11m 25s\n11complete in 11m 10s\n","name":"stdout"}],"source":"x = 1\r\nfor df in train:\r\n    if x != 10:\r\n        x += 1\r\n        continue\r\n    \r\n    print('第%d次处理开始'%x)\r\n    \r\n    print('训练集测试集合并')\r\n    y_train = df[4]\r\n    df.drop([4], axis=1, inplace=True)\r\n    len_train = len(df)\r\n    df = pd.concat((df, test))\r\n    del test\r\n    print('合并完成，提取特征')\r\n    \r\n    df = getfeature(df)\r\n    df['Pehrson'] = df['Pehrson'].fillna(df['Pehrson'].mean())\r\n    df = df.values\r\n    y_train = y_train.values\r\n    np.save('x_train_test_feature_last1000W.npy', df)\r\n    np.save('y_train_test_feature_last1000W.npy', y_train)\r\n\r\n    print('第%d次处理完成，开始训练'%x)\r\n    break","execution_count":28},{"metadata":{"id":"E5B1737E1C894A33B2AD3CD8797D9C3F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"print('划分数据集')\nx_train = df[:len_train]\nx_test = df[len_train:]\ndel df\nprint(x_train.shape, x_test.shape)","execution_count":29},{"metadata":{"id":"86090B41ED504C3DA9BC8ED5902F9F6E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"kf_n = 5\r\nkf = KFold(n_splits=kf_n, shuffle=True)\r\n\r\npre_lr = 0\r\n\r\nlr = LogisticRegression(penalty='l1', C=1, n_jobs=4)\r\n\r\nfor x_tr, x_vail in kf.split(x_train):\r\n        \r\n        lr.fit(x_train[x_tr], y_train[x_tr])\r\n        print(metrics.roc_auc_score(y_train[x_vail], lr.predict_proba(x_train[x_vail])[:, 1]))\r\n        print(metrics.log_loss(y_train[x_vail], lr.predict_proba(x_train[x_vail])[:, 1]))\r\n        pre_lr += lr.predict_proba(x_test)[:, 1]\r\n\r\npre_lr /= kf_n\r\n\r\npre_df = pre_df.rename(columns={0:'query_id', 2:'query_title_id'})\r\npre_df['prediction'] = pre_lr\r\npre_df.to_csv('lr_doc2vec_last500w.csv', index=False, header=False)","execution_count":41},{"metadata":{"id":"95732ADA5E984801859110D4B73CEB13","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"pre_lgb = 0\r\n\r\nrandom_state = 2\r\n\r\n# lgb_params = {\r\n#     \"objective\" : \"binary\",\r\n#     # \"metric\" : \"auc\",\r\n#     \"boosting\": 'gbdt',\r\n#     \"max_depth\" : -1,\r\n#     \"num_leaves\" : 5,\r\n#     \"learning_rate\" : 0.1,\r\n#     \"bagging_freq\": 5,\r\n#     \"bagging_fraction\" : 0.6,\r\n#     \"feature_fraction\" : 0.05,\r\n#     \"min_data_in_leaf\": 700,\r\n#     \"min_sum_heassian_in_leaf\": 10,\r\n#     \"tree_learner\": \"serial\",\r\n#     \"boost_from_average\": \"false\",\r\n# #    \"lambda_l1\" : 5,\r\n# #    \"lambda_l2\" : 5,\r\n#     \"bagging_seed\" : random_state,\r\n#     \"verbosity\" : 1,\r\n#     \"seed\": random_state\r\n# }\r\n\r\nlgb_params = {\r\n    'boosting_type': 'gbdt',\r\n    'objective': \"binary\",\r\n    'metric': ['binary_logloss',\"auc\"],\r\n    'num_leaves': 10,\r\n    'learning_rate': 0.05,\r\n    'feature_fraction': 0.8,\r\n    'bagging_fraction': 0.8,\r\n    'bagging_freq': 5,\r\n    'verbose': 1,\r\n    \"seed\": random_state,\r\n    \"bagging_seed\" : random_state\r\n}\r\n\r\n\r\nfor x_tr, x_vail in kf.split(x_train):\r\n        \r\n        #当x_train为ndarray时，下列数据集的划分会进行复制而占用内存\r\n        \r\n        # x_t1 = x_train[x_tr]\r\n        # y_t1 = y_train[x_tr]\r\n        \r\n        # x_t2 = x_train[x_vail]\r\n        # y_t2 = y_train[x_vail]\r\n            \r\n        lgbtr1=lgb.Dataset(x_train[x_tr], y_train[x_tr])\r\n        lgbtr2=lgb.Dataset(x_train[x_vail], y_train[x_vail])\r\n            \r\n        evals_result = {}\r\n        gbm = lgb.train(lgb_params,\r\n                          lgbtr1,\r\n                          num_boost_round=1000,\r\n                          valid_sets=lgbtr2,\r\n                          verbose_eval=50,\r\n                          early_stopping_rounds=100,\r\n                          evals_result=evals_result)\r\n                          \r\n        print(metrics.roc_auc_score(y_train[x_vail], gbm.predict(x_train[x_vail], num_iteration=gbm.best_iteration)))\r\n        pre_lgb += gbm.predict(x_test, num_iteration=gbm.best_iteration)\r\n        \r\npre_lgb /= kr_n\r\n\r\npre_df = pre_df.rename(columns={0:'query_id', 2:'query_title_id'})\r\npre_df['prediction'] = pre_lgb\r\npre_df.to_csv('lgb_doc2vec_last500w.csv', index=False, header=False)\r\n","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}